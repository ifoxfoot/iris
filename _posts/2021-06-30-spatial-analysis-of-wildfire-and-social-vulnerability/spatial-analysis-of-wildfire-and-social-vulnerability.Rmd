---
title: "Spatial Analysis of Wildfire and Social Vulnerability"
description: |
  Using a wildland fire potential raster and the CDC's social vulnerability index to locate where high wildfire risk and high social vulnerability overlap in Ventura County.
author:
  - name: iris foxfoot
    url: {}
date: 06-30-2021
output:
  distill::distill_article:
    self_contained: false
    code_folding: show code
---
## Introduction

This is a preliminary data analysis project I did for my master's project to locate where social vulnerability and high wildfire risk overlap in Ventura County. For my master's project I'm working with a student team of fellow MESM students to update the Community Wildfire Protection Plan for Ventura County in a more equitable way. This exploratory analysis was included in our workplan and was designed to prioritize communities in the Community Wildfire Protection Plan.

## Reading in the data and cleaning it a tiny bit

Click "show code" to see what packages I used and how I read in the data. I used the [Wildland Fire Potential](https://www.firelab.org/sites/default/files/images/downloads/wfp_2012_classified_metadata_faq.pdf) raster layer created by the USFS to locate areas of high fire risk, and the CDC's [Social Vulnerability Index](https://www.atsdr.cdc.gov/placeandhealth/svi/documentation/SVI_documentation_2018.html) to look at social vulnerability.

```{r setup, include=T}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
# Load the libraries into this R session
library(raster)  #Main raster library with nearly all functions used in this analysis
library(rgdal) #Spatial library - most functions used from rgdal are for vectors (shapefiles)
library(rasterVis)  #Useful for raster visualizations
library(rgeos) #Need this library for topology operations on geometries
library(dplyr)  #NOT spatial - this is a data wrangling library (is also part of tidyverse)
library(here) #sets up file path
library(sf) #also allows R to work with spatial data but as dataframes
library(sp) #allows R to work with spatial data
library(tidyverse) #for data wrangling
library(tmap) #makes interactive maps
library(kableExtra) #for tables
library(viridis) #for colors
library(janitor) # for cleaning

#setting smaller margins for plotting

#read in wildfire hazard potential raster layers

#this one has classes. 1 = low risk, 5 = highest risk, 6&7 represent water/non burnable areas
wph_cls <- raster(here("data", "WPH_data","whp2020_cls_conus.tif"))

#this one is continuous, higher values = higher fuel load 
wph_cont <- raster(here("data", "WPH_data", "whp2020_cnt_conus.tif"))

# fixing classes so that water and non-burnable areas = 0
wph_cls <- reclassify(wph_cls, rcl=c(5,7,0))

#View it
plot(wph_cls, main = "Classes of Wildfire Potential (5 = high)")

plot(wph_cont, main = "Continuous Wildfire Potential")

#read in ventura data (taken from CDC vulnerability index of CA at census level)
vuln_ca_tract <- st_read(here("data", "California", "SVI2018_CALIFORNIA_tract.shp"))
```

## Data Wrangling

Now that I have all the data I need, and in the form that I want it, it's time to wrangle! In this section of code I basically calculate the average wildfire hazard value per census tract, and this information gets turned into a new column in our vulnerability data. Then I select census tracts that have a high average wildfire hazard value and a high vulnerability score. Click "show code" to see all the steps!

```{r}
#filter for Ventura census tracts
ventura_vuln_tract <- vuln_ca_tract %>% 
  filter(COUNTY == "Ventura")

#This is like the zonal statistics tool in GIS. I'm overlaying the census 
#boundaries onto the raster of continuous fire risk and calculating the mean 
#risk in each tract. It then appends it to the polygon layer, which is the 
#census tracts of Ventura in this case.
extract_fire <- raster::extract(wph_cont, ventura_vuln_tract, 
                                method="simple", 
                                fun=mean, 
                                weights=TRUE,
                                normalizeWeights=TRUE, 
                                sp = TRUE)

#convert to sf (sf makes a polygon layer like a dataframe so you can use tidyverse commands on it)
extract_fire_sf <- st_as_sf(extract_fire)

#wrangle to show vulnerable communities
vulnerable_fire <- extract_fire_sf %>% 
  filter(quantile(RPL_THEMES, 0.75)<RPL_THEMES) %>% #top quantile of vulnerability
  filter(quantile(whp2020_cnt_conus, 0.75)<whp2020_cnt_conus) #top quantile of fire risk

#change column names, split census name up so it's not so long
vulnerable_fire <- vulnerable_fire %>% 
  rename(fire_risk_per_tract = whp2020_cnt_conus) %>% 
  rename(vulnerability_per_tract = RPL_THEMES) %>% 
  separate(LOCATION, c("census_tract", "county"), ",")
```

## Making Data Visualizations

In this next section I made a table and an interactive map. This analysis was just for internal purposes, so I kept it simple. 

```{r}
#select variables for a table
vulnerable_fire_table <- vulnerable_fire %>% 
  select("census_tract", "fire_risk_per_tract", "vulnerability_per_tract") 

#get rid of geometry info (it automatically "sticks" to the data unless you tell it not to)
st_geometry(vulnerable_fire_table) <- NULL

#table
vulnerable_fire_table %>% 
  kbl(caption = 
        "Top Quartile of Social Vulnerabilty and Fire Potential by Census Tract"
      ) %>% 
   kable_classic(full_width = T, html_font = "Cambria")

#tmap -- interactive
tmap_mode("view")
tm_basemap("OpenStreetMap.HOT") +
tm_shape(vulnerable_fire) +
tm_polygons(c("fire_risk_per_tract", "vulnerability_per_tract"), 
            alpha = 0.5, 
            id = "census_tract", 
            palette = "seq", 
            legend.reverse = T) +
    tm_facets(sync = TRUE, ncol = 2)+
  tm_layout(aes.palette = list(seq = "-viridis"))
```
## Conclusions

It turns out that wildfire risk and social vulnerability overlap in the Santa Clara River Valley of Ventura County. After doing this data exploration project, my team was able to zero in on the populations we wanted to address in the Community Wildfire Protection Plan. Our next step is to look deeper into the census data to see what type of social vulnerability these census tracts are experiencing. 

